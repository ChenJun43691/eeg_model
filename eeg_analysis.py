# ğŸ§  1ï¸âƒ£ è¼‰å…¥å¿…è¦çš„æ¨¡çµ„
import pandas as pd  # è®€å– CSV æª”æ¡ˆ
import matplotlib.pyplot as plt  # ç¹ªè£½åœ–è¡¨
import seaborn as sns  # ç¾åŒ–åœ–è¡¨
import matplotlib  # æ§åˆ¶ç¹ªåœ–ç´°ç¯€
from sklearn.decomposition import PCA  # ä¸»æˆåˆ†åˆ†æï¼ˆé™ç¶­ï¼‰
from sklearn.model_selection import train_test_split  # è¨“ç·´é›†èˆ‡æ¸¬è©¦é›†åˆ‡åˆ†
import xgboost as xgb  # XGBoost æ¨¡å‹
from sklearn.metrics import accuracy_score, classification_report  # æ¨¡å‹è©•ä¼°
from imblearn.over_sampling import SMOTE  # SMOTE å¢å¼·å°‘æ•¸é¡åˆ¥æ•¸æ“š

# è¨­å®š Matplotlib ä½¿å…¶æ”¯æ´ä¸­æ–‡
matplotlib.rcParams['font.sans-serif'] = ['Arial Unicode MS']
matplotlib.rcParams['axes.unicode_minus'] = False  

# ğŸ§  2ï¸âƒ£ è®€å– EEG æ•¸æ“š
file_path = "EEG_Scaled_data.csv"
df = pd.read_csv(file_path)

# ğŸ” 3ï¸âƒ£ æª¢è¦–æ•¸æ“šåŸºæœ¬è³‡è¨Š
print("ğŸ“Š æ•¸æ“šå‰å¹¾è¡Œï¼š")
print(df.head())  # æŸ¥çœ‹æ•¸æ“šå‰ 5 ç­†
print("\nğŸ”¢ æ•¸æ“šæ¬„ä½æ•¸ï¼š", df.shape[1])  # æŸ¥çœ‹æ¬„ä½æ•¸ï¼ˆé€šé“æ•¸ + targetï¼‰
print("\nâš ï¸ ç¼ºå¤±å€¼çµ±è¨ˆï¼š", df.isnull().sum().sum())  # æª¢æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±å€¼
df.info()  # æŸ¥çœ‹æ•¸æ“šçµæ§‹

# ğŸ” 4ï¸âƒ£ ç¢ºèª target æ˜¯å¦ç‚ºæœ€å¾Œä¸€åˆ—
print("\nğŸ” ç¢ºèª target æ˜¯å¦ç‚ºæœ€å¾Œä¸€åˆ—ï¼š", df.columns[-5:])

# ğŸ“ˆ 5ï¸âƒ£ EEG è¨Šè™Ÿè¦–è¦ºåŒ–ï¼ˆå‰ 500 å€‹æ™‚é–“é»ï¼‰
plt.figure(figsize=(10, 5))
plt.plot(df.iloc[:500, 0], label="Channel_1")  
plt.plot(df.iloc[:500, 1], label="Channel_2")
plt.legend()
plt.title("EEG è¨Šè™Ÿæ³¢å½¢ï¼ˆå‰ 500 å€‹æ™‚é–“é»ï¼‰")
plt.xlabel("æ™‚é–“é»")
plt.ylabel("ä¿¡è™Ÿå¼·åº¦")
plt.show()

# ğŸ“Š 6ï¸âƒ£ ç›®æ¨™è®Šæ•¸ (target) çš„åˆ†ä½ˆ
plt.figure(figsize=(6, 4))
sns.countplot(x=df['target'])
plt.title("ç™²ç™‡ vs. éç™²ç™‡æ¨£æœ¬æ•¸é‡")
plt.xlabel("0 = éç™²ç™‡, 1 = ç™²ç™‡")
plt.ylabel("æ¨£æœ¬æ•¸é‡")
plt.show()

# ğŸ§  7ï¸âƒ£ **é™ç¶­ï¼ˆPCAï¼Œä¸»æˆåˆ†åˆ†æï¼‰**
pca = PCA(n_components=100)  # é™åˆ° 100 ç¶­
eeg_reduced = pca.fit_transform(df.iloc[:, :-1])  # ç§»é™¤ target åªé€²è¡Œ PCA

print("é™ç¶­å¾Œçš„æ•¸æ“šå½¢ç‹€ï¼š", eeg_reduced.shape)  # ç¢ºä¿å½¢ç‹€æ­£ç¢º

# ğŸ“Œ 8ï¸âƒ£ **åˆ†å‰²æ•¸æ“šï¼ˆ80% è¨“ç·´ï¼Œ20% æ¸¬è©¦ï¼‰**
X = eeg_reduced
y = df['target']  # ç›®æ¨™è®Šæ•¸ï¼ˆ0ï¼šéç™²ç™‡ï¼Œ1ï¼šç™²ç™‡ï¼‰

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print("ğŸ“Š è¨“ç·´é›†å¤§å°ï¼š", X_train.shape)
print("ğŸ“Š æ¸¬è©¦é›†å¤§å°ï¼š", X_test.shape)

# ğŸ›  9ï¸âƒ£ **ä½¿ç”¨ SMOTE å¢å¼·ç™²ç™‡æ¨£æœ¬**
smote = SMOTE(sampling_strategy=1.0, random_state=42)  # è®“å…©é¡æ¨£æœ¬æ•¸ä¸€è‡´
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

print("ğŸ“Š SMOTE å¢å¼·å¾Œçš„è¨“ç·´é›†å¤§å°ï¼š", X_train_resampled.shape)

# âš– 1ï¸âƒ£0ï¸âƒ£ **èª¿æ•´é¡åˆ¥æ¬Šé‡ï¼ˆè®“ç™²ç™‡ (1) æ›´é‡è¦ï¼‰**
scale_pos_weight = len(y_train[y_train == 0]) / len(y_train[y_train == 1])  # è¨ˆç®—é¡åˆ¥æ¯”ä¾‹

# ğŸ”¥ 1ï¸âƒ£1ï¸âƒ£ è¨“ç·´ **XGBoost æ¨¡å‹**
model = xgb.XGBClassifier(
    n_estimators=300,  # å¢åŠ æ¨¹çš„æ•¸é‡ï¼Œè®“æ¨¡å‹å­¸ç¿’æ›´å¤šæ¨£æœ¬
    learning_rate=0.03,  # é™ä½å­¸ç¿’é€Ÿç‡ï¼Œè®“æ¨¡å‹å­¸ç¿’æ›´ç©©å®š
    max_depth=8,  # å¢åŠ æ¨¹çš„æ·±åº¦ï¼Œè®“æ¨¡å‹æ›´å¼·å¤§
    random_state=42,
    scale_pos_weight=1.5,  # å¹³è¡¡ç™²ç™‡æ¨£æœ¬çš„å½±éŸ¿
    gamma=0.2,  # å‰ªæï¼Œé˜²æ­¢éæ“¬åˆ
    min_child_weight=3,  # é™åˆ¶ç¯€é»åˆ†è£‚ï¼Œæ¸›å°‘å™ªéŸ³å½±éŸ¿
    colsample_bytree=0.85,  # ä½¿ç”¨ 85% ç‰¹å¾µï¼Œæå‡æ³›åŒ–èƒ½åŠ›
    subsample=0.85  # è¨“ç·´æ™‚ä½¿ç”¨ 85% æ•¸æ“šï¼Œé˜²æ­¢éæ“¬åˆ
)

# è¨“ç·´æ¨¡å‹ï¼ˆä½¿ç”¨å¢å¼·å¾Œçš„è¨“ç·´æ•¸æ“šï¼‰
model.fit(X_train_resampled, y_train_resampled)

# ğŸ¯ 1ï¸âƒ£2ï¸âƒ£ é€²è¡Œé æ¸¬
y_pred_proba = model.predict_proba(X_test)[:, 1]  # å–å¾—ç™²ç™‡ (1) çš„é æ¸¬æ©Ÿç‡
threshold = 0.6  # è¨­å®šåˆ†é¡é–€æª»ï¼ˆæé«˜ Precisionï¼Œé™ä½ False Positiveï¼‰
y_pred = (y_pred_proba > threshold).astype(int)  # æ ¹æ“šé–€æª»é€²è¡Œåˆ†é¡

# ğŸ“Œ 1ï¸âƒ£3ï¸âƒ£ **æ¨¡å‹è©•ä¼°**
accuracy = accuracy_score(y_test, y_pred)
print(f"âœ… XGBoost æº–ç¢ºç‡: {accuracy:.4f}")

# é¡¯ç¤ºåˆ†é¡å ±å‘Šï¼ˆPrecision, Recall, F1-scoreï¼‰
print("\nğŸ“Š åˆ†é¡å ±å‘Šï¼š")
print(classification_report(y_test, y_pred, target_names=["éç™²ç™‡ (0)", "ç™²ç™‡ (1)"]))